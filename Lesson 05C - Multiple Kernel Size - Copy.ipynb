{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lesson 05C - Multiple Kernel Size\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most of the code here is based on that [post](file:///C:/Users/ishay/Documents/Data%20Science/Coursera%20and%20practice/ML_Mastery/NLP/Model%20Improvement%20and%20Best%20Practices/How%20to%20Develop%20an%20N-gram%20Multichannel%20Convolutional%20Neural%20Network%20for%20Sentiment%20Analysis.html) from ML Mastery."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import imdb\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from keras.preprocessing import sequence\n",
    "#from keras.models import Sequential\n",
    "from keras.models import Model\n",
    "from keras.layers import Embedding\n",
    "from keras.layers import SpatialDropout1D\n",
    "from keras.layers import Convolution1D\n",
    "from keras.layers import Conv1D\n",
    "from keras.layers import GlobalMaxPooling1D\n",
    "from keras.layers import MaxPooling1D\n",
    "from keras.layers import Input\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers.merge import concatenate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "max_features = 5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_test, y_test) = imdb.load_data(num_words=max_features) # instead on nb_words="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Sequence Padding**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "maxlen = 400"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define maximum length of 400. It means that posts shoeter than 400 will be filled with 0s, and longer posts are cut."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = sequence.pad_sequences(X_train, maxlen=maxlen)\n",
    "X_test = sequence.pad_sequences(X_test, maxlen=maxlen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Now defining the model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_model(length, vocab_size):\n",
    "    # First channel\n",
    "    inputs_shape1 = Input(shape=(length,))\n",
    "    embed1 = Embedding(input_dim=vocab_size, output_dim=50)(inputs_shape1)\n",
    "    spat_drop1 = SpatialDropout1D(0.4)(embed1)\n",
    "    conv1 = Conv1D(filters=250, kernel_size=3, padding='valid', activation='relu', strides=1)(spat_drop1)\n",
    "    pool1 = MaxPooling1D(pool_size=2)(conv1)\n",
    "    flat1 = Flatten()(pool1)\n",
    "    \n",
    "    # Second channel\n",
    "    inputs_shape2 = Input(shape=(length,))\n",
    "    embed2 = Embedding(input_dim=vocab_size, output_dim=50)(inputs_shape2)\n",
    "    spat_drop2 = SpatialDropout1D(0.3)(embed2)\n",
    "    conv2 = Conv1D(filters=250, kernel_size=4, padding='valid', activation='relu', strides=1)(spat_drop2)\n",
    "    pool2 = MaxPooling1D(pool_size=2)(conv2)\n",
    "    flat2 = Flatten()(pool2)\n",
    "    \n",
    "    # Third channel\n",
    "    inputs_shape3 = Input(shape=(length,))\n",
    "    embed3 = Embedding(input_dim=vocab_size, output_dim=50)(inputs_shape3)\n",
    "    spat_drop3 = SpatialDropout1D(0.4)(embed3)\n",
    "    conv3 = Conv1D(filters=250, kernel_size=5, padding='valid', activation='relu', strides=1)(spat_drop3)\n",
    "    pool3 = MaxPooling1D(pool_size=2)(conv3)\n",
    "    flat3 = Flatten()(pool3)\n",
    "    # merge\n",
    "    merged = concatenate([flat1, flat2, flat3])\n",
    "    # FC layers\n",
    "    dense1 = Dense(250, activation='relu')(merged)\n",
    "    drop1 = Dropout(0.3)(dense1)\n",
    "    dense2 = Dense(20, activation='relu')(drop1)\n",
    "    drop2 = Dropout(0.3)(dense2)\n",
    "    output = Dense(1, activation='sigmoid')(drop2)\n",
    "    model = Model(inputs=[inputs_shape1, inputs_shape2, inputs_shape3], outputs=output)\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    print(model.summary())\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            (None, 400)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_4 (InputLayer)            (None, 400)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_5 (InputLayer)            (None, 400)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_7 (Embedding)         (None, 400, 50)      250000      input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_8 (Embedding)         (None, 400, 50)      250000      input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_9 (Embedding)         (None, 400, 50)      250000      input_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_7 (SpatialDro (None, 400, 50)      0           embedding_7[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_8 (SpatialDro (None, 400, 50)      0           embedding_8[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_9 (SpatialDro (None, 400, 50)      0           embedding_9[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_7 (Conv1D)               (None, 398, 250)     37750       spatial_dropout1d_7[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_8 (Conv1D)               (None, 397, 250)     50250       spatial_dropout1d_8[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_9 (Conv1D)               (None, 396, 250)     62750       spatial_dropout1d_9[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_7 (MaxPooling1D)  (None, 199, 250)     0           conv1d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_8 (MaxPooling1D)  (None, 198, 250)     0           conv1d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_9 (MaxPooling1D)  (None, 198, 250)     0           conv1d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "flatten_7 (Flatten)             (None, 49750)        0           max_pooling1d_7[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_8 (Flatten)             (None, 49500)        0           max_pooling1d_8[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_9 (Flatten)             (None, 49500)        0           max_pooling1d_9[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 148750)       0           flatten_7[0][0]                  \n",
      "                                                                 flatten_8[0][0]                  \n",
      "                                                                 flatten_9[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Dense)                 (None, 250)          37187750    concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 250)          0           dense_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_8 (Dense)                 (None, 20)           5020        dropout_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)             (None, 20)           0           dense_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_9 (Dense)                 (None, 1)            21          dropout_6[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 38,093,541\n",
      "Trainable params: 38,093,541\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = create_model(maxlen, max_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Fitting the model**\n",
    "\n",
    "I must enter X_train three times (also X_test), one for each channel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-437853b9ce75>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mepochs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m32\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m h = model.fit([X_train, X_train, X_train], y_train, batch_size=batch_size, epochs=epochs, \n\u001b[0m\u001b[0;32m      4\u001b[0m               validation_data=([X_test,X_test,X_test], y_test), verbose=2)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "epochs = 5\n",
    "batch_size = 32\n",
    "h = model.fit([X_train, X_train, X_train], y_train, batch_size=batch_size, epochs=epochs, \n",
    "              validation_data=([X_test,X_test,X_test], y_test), verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "loss, accuracy = model.evaluate(X_train, y_train, verbose=0)\n",
    "print(\"Training: accuracy = %f  ;  loss = %f\" % (accuracy, loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "loss, accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"Validation: accuracy1 = %f  ;  loss1 = %f\" % (accuracy, loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# A good way to view the shape of each layer. Can be printed after the compile function\n",
    "print(model.summary())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
